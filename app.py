import streamlit as st
import os
import time
from pathlib import Path

from langchain.document_loaders import PyPDFLoader
from langchain.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

# í˜ì´ì§€ êµ¬ì„±
st.set_page_config(
    page_title="W Club AI ì»¨ì‹œì–´ì§€",
    page_icon="ğŸ’",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "vector_store_created" not in st.session_state:
    st.session_state.vector_store_created = False

# ì»¤ìŠ¤í…€ CSS
st.markdown(
    """
    <style>
    .stApp {
        background-color: #f9f9f9;
    }
    .main-header {
        font-size: 2.5rem;
        color: #6c2d82;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .stChatMessage {
        background-color: white;
        border-radius: 15px;
        padding: 15px;
        margin-bottom: 15px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        border-left: 5px solid #6c2d82;
    }
    .stChatMessage.user {
        border-left: 5px solid #4a8fe7;
    }
    .stTextInput>div>div>input {
        border-radius: 20px;
    }
    .status-box {
        background-color: #f0f0f0;
        border-radius: 10px;
        padding: 20px;
        margin-bottom: 20px;
        text-align: center;
    }
    .sidebar-header {
        font-size: 1.5rem;
        color: #6c2d82;
        margin-bottom: 1rem;
        text-align: center;
    }
    .footer {
        text-align: center;
        margin-top: 40px;
        color: #666;
        font-size: 0.8rem;
    }
    .api-input {
        background-color: #f0f0f0;
        padding: 15px;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)
PDF_FILE = DATA_DIR / "wclub_manual.pdf"
VECTOR_DB_DIR = DATA_DIR / "chroma_db"

# ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.markdown('<div class="sidebar-header">W Club AI ì»¨ì‹œì–´ì§€</div>', unsafe_allow_html=True)
    
    # ë¡œê³  ì´ë¯¸ì§€ (ì›í•˜ëŠ” ì´ë¯¸ì§€ë¡œ ë³€ê²½)
    st.image("https://i.ibb.co/fDBHYpP/wclub-logo.png", width=200)
    
    st.markdown("---")
    
    # API í‚¤ ì…ë ¥ ë°•ìŠ¤
    st.markdown('<div class="api-input">', unsafe_allow_html=True)
    st.markdown("### OpenAI API í‚¤ ì„¤ì •")
    openai_api_key = st.text_input("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password", placeholder="sk-...")
    if openai_api_key:
        os.environ["OPENAI_API_KEY"] = openai_api_key
        st.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
    st.markdown("### ğŸ’¬ ëŒ€í™” ê´€ë¦¬")
    if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    
    # ì‚¬ìš© ì•ˆë‚´
    st.markdown("### â„¹ï¸ ì‚¬ìš© ì•ˆë‚´")
    with st.expander("ì‚¬ìš© ë°©ë²•", expanded=False):
        st.markdown("""
        1. OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
        2. ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  AIì™€ ëŒ€í™”í•˜ì„¸ìš”.
        """)

# ë²¡í„° ìŠ¤í† ì–´ ìë™ ìƒì„± í•¨ìˆ˜
@st.cache_resource
def get_vector_store():
    """ë²¡í„° ìŠ¤í† ì–´ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤."""
    # ì´ë¯¸ ìƒì„±ëœ ë²¡í„° ìŠ¤í† ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
    if os.path.exists(VECTOR_DB_DIR):
        try:
            embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small",
                openai_api_key=os.environ.get("OPENAI_API_KEY", "")
            )
            return Chroma(
                persist_directory=str(VECTOR_DB_DIR),
                embedding_function=embeddings
            )
        except Exception:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒˆë¡œ ìƒì„±
            pass
    
    # PDF íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´
    if not os.path.exists(PDF_FILE):
        # ìƒ˜í”Œ ë°ì´í„°ë¡œ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        from langchain.schema import Document
        
        # ìƒ˜í”Œ ë¬¸ì„œ ìƒì„±
        sample_docs = [
            Document(
                page_content="W Clubì€ ê³ í’ˆê²© ë‚¨ë…€ ë§¤ì¹­ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. íšŒì›ë‹˜ë“¤ì˜ í–‰ë³µí•œ ë§Œë‚¨ì„ ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                metadata={"source": "sample"}
            ),
            Document(
                page_content="ì•½ì† ì¥ì†Œ ë³€ê²½ì€ ì•½ì†ì¼ 2ì¼ ì „ ì—´ë¦¬ëŠ” ëŒ€í™”ë°©ì„ í†µí•´ ìƒëŒ€ íšŒì›ê³¼ í˜‘ì˜ í›„ ì§„í–‰í•´ì£¼ì„¸ìš”.",
                metadata={"source": "sample"}
            ),
            Document(
                page_content="ë±ƒì§€ ì¸ì¦ì„ ì›í•˜ì‹œë©´ ì•± ë‚´ì—ì„œ [ë‚´ì •ë³´ > í”„ë¡œí•„ ìˆ˜ì • > ë‚´ í”„ë¡œí•„ ìˆ˜ì • > ë±ƒì§€ ì¶”ê°€/ë³€ê²½í•˜ê¸°] ë©”ë‰´ë¥¼ í†µí•´ ì‹ ì²­í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                metadata={"source": "sample"}
            ),
            Document(
                page_content="ì•½ì† ì·¨ì†ŒëŠ” [ë‚´ì •ë³´ > ì•½ì†ê´€ë¦¬]ì—ì„œ í•˜ì‹¤ ìˆ˜ ìˆìœ¼ë©°, ìƒëŒ€ë°©ì— ëŒ€í•œ ë°°ë ¤ë¡œ ì·¨ì†Œ ì‚¬ìœ ë¥¼ ê¼­ ì•Œë ¤ì£¼ì„¸ìš”.",
                metadata={"source": "sample"}
            ),
            Document(
                page_content="W Club ë§¤ì¹­ ì„±ê³µë¥ ì„ ë†’ì´ê¸° ìœ„í•´ì„œëŠ” í”„ë¡œí•„ ì‚¬ì§„ê³¼ ìê¸°ì†Œê°œë¥¼ ì •ì„±ê» ì‘ì„±í•´ì£¼ì„¸ìš”.",
                metadata={"source": "sample"}
            ),
        ]
        
        try:
            embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small",
                openai_api_key=os.environ.get("OPENAI_API_KEY", "")
            )
            
            # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ê°€ ìˆìœ¼ë©´ ì‚­ì œ
            if os.path.exists(VECTOR_DB_DIR):
                import shutil
                shutil.rmtree(VECTOR_DB_DIR)
            
            # ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥
            return Chroma.from_documents(
                sample_docs, 
                embeddings,
                persist_directory=str(VECTOR_DB_DIR)
            )
        except Exception as e:
            st.error(f"ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    else:
        # PDF íŒŒì¼ì´ ìˆëŠ” ê²½ìš° PDFë¡œ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        try:
            # PDF ë¡œë“œ ë° ë¶„í• 
            loader = PyPDFLoader(str(PDF_FILE))
            pages = loader.load_and_split()
            
            # í…ìŠ¤íŠ¸ ë¶„í• 
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
            docs = text_splitter.split_documents(pages)
            
            # ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
            embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small",
                openai_api_key=os.environ.get("OPENAI_API_KEY", "")
            )
            
            # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ê°€ ìˆìœ¼ë©´ ì‚­ì œ
            if os.path.exists(VECTOR_DB_DIR):
                import shutil
                shutil.rmtree(VECTOR_DB_DIR)
            
            # ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥
            return Chroma.from_documents(
                docs, 
                embeddings,
                persist_directory=str(VECTOR_DB_DIR)
            )
        except Exception as e:
            st.error(f"ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

# ì±—ë´‡ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
def get_prompt_template():
    return ChatPromptTemplate.from_template("""
    ë‹¹ì‹ ì€ ë‚¨ë…€ ë°ì´í„° ë§¤ì¹­ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ë”ë¸”ìœ í´ëŸ½ì˜ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ AI ë¹„ì„œì…ë‹ˆë‹¤.
    ë¬¸ì˜ ê²Œì‹œíŒì— ê³ ê°ì´ ë¬¸ì˜í•œ ë‚´ìš©ì„ ë‹µë³€í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
    ê³ ê°ì˜ ì§ˆë¬¸ì— ê³µê°í•˜ëŠ” í‘œí˜„ìœ¼ë¡œ ë‹µë³€ì„ ì‹œì‘í•˜ê³ , ë¬¸ì œ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•˜ì„¸ìš”.
    ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ê³ ê° ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.

    ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”:
    1. ë¬¸ì¥ì˜ ì‹œì‘ì€ "ì•ˆë…•í•˜ì„¸ìš”. W Club AI ì»¨ì‹œì–´ì§€ ì…ë‹ˆë‹¤." ë¡œ ì‹œì‘í•˜ì„¸ìš”.
    2. ê³ ê°ì´ ë¶€ì •ì ì¸ ê°ì •ì„ í‘œí˜„í•˜ëŠ” ê²½ìš° ê³µê°í•˜ëŠ” í‘œí˜„ìœ¼ë¡œ ë‹µë³€ì„ ì‹œì‘í•˜ì„¸ìš”.
    3. ë¬¸ì¥ì˜ ëì€ ê³ ê°ì˜ ì‹¬ë¦¬ ìƒíƒœë¥¼ íŒŒì•…í•˜ì—¬ ì •ì¤‘í•˜ê²Œ ì¸ì‚¬ë¡œ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.
    4. footerëŠ” "ì§„ì‹¬ì„ ë‹´ì•„, Sincerely Yours, Concierge 'Worthy or Wealthy'  W Club - Private Social Club Members Only" ë¡œ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.
    5. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì—ì„œë§Œ ì •ë³´ë¥¼ ì°¾ì•„ ë‹µë³€í•˜ì„¸ìš”.
    6. ë‹µë³€ì„ ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš° "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­/ë¬¸ì˜ ì£¼ì‹  ì‚¬í•­ì€ ì¶”ê°€ì ìœ¼ë¡œ í™•ì¸ í›„ì— ë¹ ë¥¸ ì‹œì¼ë‚´ì— ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."ë¼ê³  ì‘ë‹µí•˜ì„¸ìš”.
    7. ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ê³µì†í•œ ë§íˆ¬ë¡œ 3ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
    8. ê³ ê°ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ì§‘ì¤‘í•˜ì„¸ìš”. í•´ê²°ì±…ì´ ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ì´ë£¨ì–´ì§„ ê²½ìš° ëª…í™•í•œ ë‹¨ê³„ë³„ ì•ˆë‚´ë¥¼ ì œê³µí•˜ì„¸ìš”.
    9. ê³ ê°ì˜ ì§ˆë¬¸ì— ê³µê°í•˜ëŠ” í‘œí˜„ìœ¼ë¡œ ë‹µë³€ì„ ì‹œì‘í•˜ê³ , ë¬¸ì œ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•˜ì„¸ìš”.
    10. ë§ˆë¬´ë¦¬ëŠ” "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ë‚˜ ì–¸ì œë“  í¸í•˜ê²Œ ë§ì”€ ë¶€íƒë“œë¦½ë‹ˆë‹¤.  ê°ì‚¬í•©ë‹ˆë‹¤." ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.
    11. ë¬¸ì¥ì˜ ê°€ë…ì„±ì´ ì¢‹ê²Œ ì¤„ë°”ê¿ˆ ë“±ì„ ì ì ˆí•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”. ëª¨ë“  ë¬¸ì¥ì€ 1ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì¤„ë°”ê¿ˆí•˜ì„¸ìš”.
    12. ìì„¸í•œ ë‹µë³€ì„ ìœ„í•´ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì€ ìµœëŒ€í•œ ë°˜ì˜í•˜ì„¸ìš”.
    13. ì²˜ìŒë¶€í„° ëê¹Œì§€ ëª¨ë“  ë¬¸ì¥ì€ ë§¤ìš° ì •ì¤‘í•˜ê²Œ í‘œí˜„í•˜ì„¸ìš”.

    ì§ˆë¬¸: {question}
    ì°¸ê³  ë¬¸ì„œ: {context}

    ë‹µë³€:
    """)

# ì±—ë´‡ ì²´ì¸ ìƒì„±
def get_chat_chain():
    vector_store = get_vector_store()
    if vector_store is None:
        return None
    
    retriever = vector_store.as_retriever()
    
    # ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)
    
    # ëª¨ë¸ ì„¤ì •
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2,
        streaming=True,
        openai_api_key=os.environ.get("OPENAI_API_KEY", "")
    )
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
    prompt = get_prompt_template()
    
    # RAG ì²´ì¸ êµ¬ì¶•
    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    
    return rag_chain

# ë©”ì¸ ì„¹ì…˜
col1, col2, col3 = st.columns([1, 3, 1])
with col2:
    st.markdown('<h1 class="main-header">W Club AI ì»¨ì‹œì–´ì§€</h1>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">ë”ë¸”ìœ í´ëŸ½ íšŒì›ë‹˜ë“¤ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤</div>', unsafe_allow_html=True)

# ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
system_ready = os.environ.get("OPENAI_API_KEY", "")

if not system_ready:
    st.markdown('<div class="status-box">', unsafe_allow_html=True)
    st.warning("âš ï¸ ì‹œì‘í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.markdown('</div>', unsafe_allow_html=True)

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
chat_container = st.container(height=500)
with chat_container:
    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        avatar = "ğŸ‘¤" if message["role"] == "user" else "ğŸ¤–"
        with st.chat_message(message["role"], avatar=avatar):
            st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...", disabled=not system_ready)
if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with chat_container:
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(user_input)
    
    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„±
    with chat_container:
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            message_placeholder = st.empty()
            full_response = ""
            
            # ì±—ë´‡ ì²´ì¸ ìƒì„±
            chat_chain = get_chat_chain()
            
            if chat_chain is None:
                full_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                message_placeholder.markdown(full_response)
            else:
                try:
                    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í‘œì‹œ
                    with st.spinner("ì‘ë‹µì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        for chunk in chat_chain.stream(user_input):
                            full_response += chunk
                            message_placeholder.markdown(full_response + "â–Œ")
                            time.sleep(0.01)
                        
                        message_placeholder.markdown(full_response)
                except Exception as e:
                    full_response = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    message_placeholder.markdown(full_response)
    
    # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": full_response})
    
    # ì±„íŒ… ì»¨í…Œì´ë„ˆë¥¼ ì•„ë˜ë¡œ ìŠ¤í¬ë¡¤
    st.rerun()

# í‘¸í„°
st.markdown('<div class="footer">Â© 2024 W Club AI ì»¨ì‹œì–´ì§€ - Private Social Club Members Only</div>', unsafe_allow_html=True) 